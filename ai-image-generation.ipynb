{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3d64ce-821f-476b-8aac-d49f5c606df5",
   "metadata": {},
   "source": [
    "# AI Image Generation with Stable Diffusion\n",
    "\n",
    "This notebook demonstrates how to generate images from textual descriptions using a pre-trained Stable Diffusion model. We will walk through the entire process, from setting up the environment to loading the model and generating an image based on a custom prompt. The specific model used is `runwayml/stable-diffusion-v1-5`, a powerful and popular checkpoint for creating high-quality images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3549b-d075-43b1-aefa-c1d7c7e5cc81",
   "metadata": {},
   "source": [
    "### 1. Setting Up the Environment\n",
    "\n",
    "Before we begin, we need to install the necessary Python libraries. The `requirements.txt` file specifies all the dependencies for this project. The command below uses `pip` to install them.\n",
    "\n",
    "* **`diffusers`**: A core Hugging Face library that provides pre-trained diffusion models and pipelines, like Stable Diffusion.\n",
    "* **`transformers`**: Another essential Hugging Face library that provides general-purpose architectures (like CLIP) used by the Stable Diffusion pipeline.\n",
    "* **`accelerate`**: A library from Hugging Face that optimizes PyTorch code to run efficiently on various hardware setups, including GPUs.\n",
    "* **`scipy`**: A scientific computing library that is a dependency for some schedulers in the `diffusers` library.\n",
    "* **`safetensors`**: A secure and fast file format for storing model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa554ef-b866-4337-9e21-42b3720f8700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (0.34.0)\n",
      "Requirement already satisfied: transformers in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (4.53.3)\n",
      "Requirement already satisfied: accelerate in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: scipy in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: safetensors in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: importlib_metadata in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from diffusers->-r requirements.txt (line 1)) (8.7.0)\n",
      "Requirement already satisfied: filelock in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from diffusers->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.27.0 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from diffusers->-r requirements.txt (line 1)) (0.33.4)\n",
      "Requirement already satisfied: numpy in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from diffusers->-r requirements.txt (line 1)) (2.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from diffusers->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from diffusers->-r requirements.txt (line 1)) (2.32.4)\n",
      "Requirement already satisfied: Pillow in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from diffusers->-r requirements.txt (line 1)) (11.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 2)) (0.21.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from transformers->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: psutil in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from accelerate->-r requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from accelerate->-r requirements.txt (line 3)) (2.7.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from huggingface-hub>=0.27.0->diffusers->-r requirements.txt (line 1)) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from huggingface-hub>=0.27.0->diffusers->-r requirements.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from huggingface-hub>=0.27.0->diffusers->-r requirements.txt (line 1)) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (3.3.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from importlib_metadata->diffusers->-r requirements.txt (line 1)) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from requests->diffusers->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from requests->diffusers->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from requests->diffusers->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from requests->diffusers->-r requirements.txt (line 1)) (2025.7.9)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /media/heytanix/Shared/JupyterLabEnvironment/Jupyter3_13/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate->-r requirements.txt (line 3)) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e2f95-7cd8-4cb0-954b-dc9710f59f40",
   "metadata": {},
   "source": [
    "### 2. Importing Necessary Libraries\n",
    "\n",
    "With the dependencies installed, we can now import the modules we'll use throughout the notebook.\n",
    "\n",
    "* **`StableDiffusionPipeline`**: The primary class from the `diffusers` library that encapsulates the entire text-to-image generation process.\n",
    "* **`torch`**: The fundamental deep learning framework (PyTorch) used to perform tensor computations and manage GPU operations.\n",
    "* **`PIL.Image`**: A module from the Pillow library for opening, manipulating, and saving many different image file formats.\n",
    "* **`os`**: A standard Python library for interacting with the operating system, which is useful for creating directories.\n",
    "* **`datetime`**: A library for working with dates and times, which we'll use to create unique filenames for our generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb806245-ecea-4cc2-91b4-389f067c6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bcb6c8-0976-4575-a403-c6b5c6ce05ad",
   "metadata": {},
   "source": [
    "### 3. Hardware Configuration\n",
    "\n",
    "To ensure fast performance, we'll first verify that a CUDA-enabled GPU is available and then set it as the primary device for all computations. Image generation is very resource-intensive, and a GPU is essential for reasonable processing times.\n",
    "\n",
    "This block will:\n",
    "* Confirm **GPU availability**.\n",
    "* Select `\"cuda\"` as the computation **device**.\n",
    "* Set the data type to `torch.float16` for optimized memory usage and speed on modern GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797b83ce-faee-4b32-85ec-07c4e2aedfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available True\n",
      "Using device: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "PyTorch version: 2.7.1+cu126\n",
      "GPU Memory Summary: |===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# For checking if GPU is available\n",
    "if not torch.cuda.is_available(): #If Torch discovers no GPU\n",
    "    raise RuntimeError(\"GPU Unavailable, Ensure PyTorch was installed with CUDA support.\")\n",
    "    #Raises a Runtime Error stating that the local device Has no CUDA enabled GPU\n",
    "\n",
    "print(\"CUDA Available\", torch.cuda.is_available()) #If CUDA is available prints \"CUDA Available\"\n",
    "print(\"Using device:\", torch.cuda.get_device_name()) #If CUDA is available prints the CUDA device being used\n",
    "print(\"PyTorch version:\", torch.__version__) #Prints the version of Torch being used\n",
    "print(\"GPU Memory Summary:\", torch.cuda.memory_summary()) #Prints the summary of the GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c1da4-b8de-4861-9577-99948f8dd204",
   "metadata": {},
   "source": [
    "### 4. Configuring the Inference Device\n",
    "\n",
    "Here, we explicitly set the computational device to `\"cuda\"`. This instructs PyTorch to allocate the model and perform all related calculations (inferences) on the GPU. Using `torch.float16` instead of the default `torch.float32` allows for faster computations and reduced memory usage on compatible GPUs by using half-precision floating-point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0033bb-4eeb-4306-8c65-3cdcf3d98fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0218fc-e19e-4edb-b7d6-d86eb0aedccf",
   "metadata": {},
   "source": [
    "### 5. Loading the Stable Diffusion Model\n",
    "\n",
    "This is where we load the pre-trained **Stable Diffusion v1.5 model** from the Hugging Face Hub.\n",
    "\n",
    "* `StableDiffusionPipeline.from_pretrained(...)` downloads the model weights and configuration. **Note: The first time you run this, it will download several gigabytes of data.**\n",
    "* We pass our `model_id` and specify the `torch_dtype` for half-precision optimization.\n",
    "* `pipe.to(device)` moves the entire pipeline onto the GPU memory.\n",
    "* The optional `safety_checker` line disables a feature that filters potentially unsafe content. This can prevent images from being blacked out if the model's content classifier is overly sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf4cfa1-8134-407a-b1aa-a318e5d230f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bf17cced394f068629d258fd687776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb151e497b048ee9d5abf474fe61bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  49%|####9     | 1.18G/2.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109d0dba53754a3db4879af24d3a76e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:  23%|##2       | 1.00G/4.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/19da7aaa4b880e59d56843f1fcb4dd9b599c28a1d9d9af7c1143057c8ffae9f1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&Expires=1751445740&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTQ0NTc0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyLzE5ZGE3YWFhNGI4ODBlNTlkNTY4NDNmMWZjYjRkZDliNTk5YzI4YTFkOWQ5YWY3YzExNDMwNTdjOGZmYWU5ZjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=qL-5w58vFsWoYLqRl7lg6mfBnGVcmQtFA9TWgUwnKpWnkvk%7ENeIO6vbsLQjXMeLb0LkyLhdwQ28RHXavx1ugbmpFFf5AYxrIIhvUFVSFC42Tdw9ypIOTwrn7C2k-rpDRRbLl%7EPPvtjFYFujwGLSpSCT5gnZp4nInbwrB8tzqiVxQkbBEA3dyRUO7N1%7EF0eh37naGrEjZRqu7S703ahODcF3DutIF9ep3KiYUnFYQjjhoRfJH03r2ubp4hPo9BpCcUjDxmpzE18Q6qtnUBfLxMiIyHrEq7VrCtkdB65TOHdAKomLXCFdmpSJEBOmZDi7BCAZ1d4%7EZSxF2Lq4wqFZwNg__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4687ea6988da41edb11191b62759aa92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:  37%|###6      | 2.02G/5.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/19da7aaa4b880e59d56843f1fcb4dd9b599c28a1d9d9af7c1143057c8ffae9f1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&Expires=1751445740&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1MTQ0NTc0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyLzE5ZGE3YWFhNGI4ODBlNTlkNTY4NDNmMWZjYjRkZDliNTk5YzI4YTFkOWQ5YWY3YzExNDMwNTdjOGZmYWU5ZjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=qL-5w58vFsWoYLqRl7lg6mfBnGVcmQtFA9TWgUwnKpWnkvk%7ENeIO6vbsLQjXMeLb0LkyLhdwQ28RHXavx1ugbmpFFf5AYxrIIhvUFVSFC42Tdw9ypIOTwrn7C2k-rpDRRbLl%7EPPvtjFYFujwGLSpSCT5gnZp4nInbwrB8tzqiVxQkbBEA3dyRUO7N1%7EF0eh37naGrEjZRqu7S703ahODcF3DutIF9ep3KiYUnFYQjjhoRfJH03r2ubp4hPo9BpCcUjDxmpzE18Q6qtnUBfLxMiIyHrEq7VrCtkdB65TOHdAKomLXCFdmpSJEBOmZDi7BCAZ1d4%7EZSxF2Lq4wqFZwNg__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048fa81e2fe742ba8cd39f6f1bcd31b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:  48%|####8     | 3.19G/6.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b111a249bd24c848ecdb39a2de0706d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ")\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "#Optional: Turn off safety checker\n",
    "pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3cf27-9d5c-4def-a3b2-fad304f6727f",
   "metadata": {},
   "source": [
    "### 6. Generating an Image from a Text Prompt\n",
    "\n",
    "Now for the creative part! We define a text `prompt` that describes the image we want to create.\n",
    "\n",
    "* **`prompt`**: The textual description that guides the AI. The more descriptive the prompt, the more detailed the output.\n",
    "* **`num_inference_steps`**: This parameter controls how many denoising steps the model takes. A higher number can lead to a more refined image but will take longer to generate. A value between 20-50 is typically a good balance.\n",
    "\n",
    "The `pipe()` function takes the prompt and other parameters, runs the generation process, and returns a result object. We access the generated image with `.images[0]` and use `.show()` to display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3545edea-8c40-43ef-825d-1f22ed7962b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39749a0385b422ca7b70d20ddae2958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected locale \"C\" with character encoding \"ANSI_X3.4-1968\", which is not UTF-8.\n",
      "Qt depends on a UTF-8 locale, and has switched to \"C.UTF-8\" instead.\n",
      "If this causes problems, reconfigure your locale. See the locale(1) manual\n",
      "for more information.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A robotic Cat\"\n",
    "\n",
    "num_inference_steps = 30\n",
    "\n",
    "generated_image = pipe(prompt, num_inference_steps=num_inference_steps).images[0]\n",
    "generated_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
